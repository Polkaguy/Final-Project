{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rpers\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.core import datetools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Final Model\n",
    "This is the final model for the classification methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition\n",
    "The following code imports and validates the LendingClub data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "converters = dict(\n",
    "    id=str,\n",
    "    desc=str,\n",
    "    hardship_type=str,\n",
    "    hardship_reason=str,\n",
    "    hardship_status=str,\n",
    "    hardship_loan_status=str,\n",
    "    verification_status_joint=str\n",
    ")\n",
    "dates = [\n",
    "    'next_pymnt_d',\n",
    "    'hardship_start_date',\n",
    "    'hardship_end_date',\n",
    "    'payment_plan_start_date',\n",
    "    'earliest_cr_line',\n",
    "    'issue_d'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./Source Data/Loan Data/LoanStats3a_securev1.csv\n",
      "Reading ./Source Data/Loan Data/LoanStats3b_securev1.csv\n",
      "Reading ./Source Data/Loan Data/LoanStats3c_securev1.csv\n",
      "Reading ./Source Data/Loan Data/LoanStats3d_securev1.csv\n",
      "Reading ./Source Data/Loan Data/LoanStats_securev1_2016Q1.csv\n",
      "Reading ./Source Data/Loan Data/LoanStats_securev1_2016Q2.csv\n",
      "Reading ./Source Data/Loan Data/LoanStats_securev1_2016Q3.csv\n",
      "Reading ./Source Data/Loan Data/LoanStats_securev1_2016Q4.csv\n",
      "Reading ./Source Data/Loan Data/LoanStats_securev1_2017Q1.csv\n",
      "Reading ./Source Data/Loan Data/LoanStats_securev1_2017Q2.csv\n",
      "Reading ./Source Data/Loan Data/LoanStats_securev1_2017Q3.csv\n",
      "Reading ./Source Data/Loan Data/LoanStats_securev1_2017Q4.csv\n",
      "Reading ./Source Data/Loan Data/LoanStats_securev1_2018Q1.csv\n",
      "(1873317, 152)\n"
     ]
    }
   ],
   "source": [
    "# Imports loan data\n",
    "\n",
    "df = pd.DataFrame()\n",
    "basepath='./Source Data/Loan Data/'\n",
    "files = os.listdir(basepath)\n",
    "csvs = []\n",
    "\n",
    "for file in files:\n",
    "    if re.match('.*csv$',file):\n",
    "        csvs += [file]\n",
    "\n",
    "if 0:\n",
    "    #ignore this - was trying to pickle the data into\n",
    "    #formats like feather, hdf5, native python pickling, etc\n",
    "    # but found issues on python 3.7\n",
    "    df=pd.read_pickle(basepath+'df.pkl')\n",
    "else:\n",
    "    cols = df.dtypes\n",
    "    for csv in csvs:\n",
    "        path = basepath + csv\n",
    "        print(\"Reading\",path)\n",
    "        tdf = pd.read_csv(path,header=1,low_memory=False)\n",
    "        df=df.append(tdf)\n",
    "    \n",
    "df.reset_index(inplace=True) # This will help with joining back data if necessary.\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_data = {}\n",
    "for column in df.columns:\n",
    "    has_data[column] = len(df[column].dropna())\n",
    "#print(len(has_data))\n",
    "#has_data\n",
    "\n",
    "order_has_data=sorted(has_data, key=lambda dict_key: has_data[dict_key])\n",
    "\n",
    "top_sparse=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1873317, 152)\n"
     ]
    }
   ],
   "source": [
    "# Convert dates to datetime\n",
    "df['issue_d'] = pd.to_datetime(df['issue_d'])\n",
    "df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'])\n",
    "\n",
    "#determine age of credit line prior to loan issue and convert to integer\n",
    "# days of credit history\n",
    "df['earliest_cr_line'] = (df['issue_d']-df['earliest_cr_line']).dt.days\n",
    "\n",
    "# convert issue_d to a year to consider economic conditions\n",
    "#SHOULD WE GO TO QUARTERS?\n",
    "df['issue_d'] = df['issue_d'].dt.year\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020552, 36)\n"
     ]
    }
   ],
   "source": [
    "# Limit to loans that are paid in full or written off. Uses dates so that \n",
    "# loans that are delinquent are not disproportionaltely dropped from data\n",
    "\n",
    "mature_filter = (df['loan_status']=='Fully Paid')|(df['loan_status']=='Charged Off')\n",
    "#mature_filter = (df['loan_status']=='Fully Paid')\n",
    "#latest_mature = df[~mature_filter]['issue_d'].min()\n",
    "#latest_mature\n",
    "#reduced_df = df[df['issue_d']<=latest_mature]\n",
    "reduced_df = df[mature_filter] # Pulls only loans that are charged off or paid in full.\n",
    "#\n",
    "## Use my documentation to filter to only \n",
    "data_dict = pd.read_excel('./Source Data/LCDataDictionary.xlsx',sheet_name='LoanStats')\n",
    "features = list(data_dict[data_dict['Useful Predictor']=='Yes']['LoanStatNew'].values)\n",
    "kaggle_features=[\"addr_state\", \"annual_inc\", \"delinq_2yrs\", \"desc\", \"dti\", \"earliest_cr_line\", \"emp_length\",\n",
    "                 \"emp_title\", \"grade\", \"home_ownership\", \"id\", \"inq_fi\", \"inq_last_6mths\", \"installment\",\n",
    "                 \"int_rate\", \"loan_amnt\", \"loan_status\", \"mths_since_last_delinq\", \"mths_since_last_major_derog\",\n",
    "                 \"mths_since_last_record\", \"open_acc\", \"pub_rec\", \"purpose\", \"pymnt_plan\", \"revol_bal\",\n",
    "                 \"revol_util\", \"sub_grade\", \"term\", \"title\", \"total_acc\", \"url\", \"verification_status\", \"zip_code\"]\n",
    "#reduced_df=reduced_df[features]\n",
    "non_kaggle_features=['application_type','fico_range_low','fico_range_high',\"total_pymnt\"]\n",
    "reduced_df=reduced_df[kaggle_features+non_kaggle_features]\n",
    "\n",
    "# Combines fields when necessary\n",
    "reduced_df['fico_est'] = (reduced_df['fico_range_low']+reduced_df['fico_range_high'])/2\n",
    "\n",
    "reduced_df.drop(columns=['fico_range_low','fico_range_high'],inplace=True)\n",
    "\n",
    "print(reduced_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup our df\n",
    "backup_df = reduced_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restore our df\n",
    "reduced_df = backup_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020552, 28)\n"
     ]
    }
   ],
   "source": [
    "# Convert strings to numbers emp_length, int_rate, revol_util\n",
    "emp_length_map={'10+ years':10, '< 1 year':0, '1 year':1, '3 years':3, '8 years':8, '9 years':9,\n",
    "                '4 years':4, '5 years':5, '6 years':6, '2 years':2, '7 years':7}\n",
    "\n",
    "reduced_df['emp_length']=reduced_df['emp_length'].replace(pd.Series(emp_length_map))\n",
    "\n",
    "grade_map={\"A\":1,\"B\":2,\"C\":3,\"D\":4,\"E\":5,\"F\":6,\"G\":7}\n",
    "reduced_df['grade']=reduced_df['grade'].replace(pd.Series(grade_map))\n",
    "\n",
    "reduced_df['int_rate']=reduced_df['int_rate'].apply(lambda x: float(x[:-1]))\n",
    "reduced_df['revol_util']=reduced_df['revol_util'].apply(lambda x:\n",
    "                                                        x[:-1] if isinstance(x, str) else np.nan).astype(float)\n",
    "\n",
    "reduced_df['earliest_cr_line']=reduced_df['earliest_cr_line'].apply(lambda x:\n",
    "                                                        0.0 if np.isnan(x) else x)\n",
    "\n",
    "reduced_df.drop(columns=['title','emp_title','desc','url','id','sub_grade','addr_state','zip_code'],inplace=True)\n",
    "\n",
    "print(reduced_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'home_ownership_MORTGAGE', 'home_ownership_OTHER', 'purpose_renewable_energy', 'application_type_Joint App', 'purpose_house', 'term_ 60 months', 'purpose_moving', 'purpose_educational', 'purpose_other', 'verification_status_Verified', 'purpose_medical', 'home_ownership_RENT', 'home_ownership_OWN', 'purpose_debt_consolidation', 'purpose_wedding', 'purpose_credit_card', 'verification_status_Source Verified', 'purpose_major_purchase', 'purpose_small_business', 'loan_status_Fully Paid', 'purpose_home_improvement', 'purpose_vacation', 'home_ownership_NONE'}\n",
      "(1020552, 44)\n"
     ]
    }
   ],
   "source": [
    "seta=set(reduced_df.columns)\n",
    "\n",
    "reduced_df=pd.get_dummies(data=reduced_df,columns=['pymnt_plan','loan_status','application_type','term',\n",
    "                                                   'verification_status',\n",
    "                                                   'home_ownership','purpose'],\n",
    "                          drop_first=True)\n",
    "\n",
    "\n",
    "setb=set(reduced_df.columns)\n",
    "print(setb-seta)\n",
    "print(reduced_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to treat NaN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's remove majority NaN columns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mths_since_last_record 172185\n",
      "1 mths_since_last_major_derog 264308\n",
      "2 inq_fi 296093\n",
      "3 mths_since_last_delinq 503506\n",
      "4 emp_length 965386\n",
      "5 revol_util 1019945\n",
      "6 dti 1020435\n",
      "7 inq_last_6mths 1020551\n",
      "8 annual_inc 1020552\n",
      "9 delinq_2yrs 1020552\n",
      "10 earliest_cr_line 1020552\n",
      "11 grade 1020552\n",
      "12 installment 1020552\n",
      "13 int_rate 1020552\n",
      "14 loan_amnt 1020552\n",
      "15 open_acc 1020552\n",
      "16 pub_rec 1020552\n",
      "17 revol_bal 1020552\n",
      "18 total_acc 1020552\n",
      "19 total_pymnt 1020552\n",
      "20 fico_est 1020552\n",
      "21 loan_status_Fully Paid 1020552\n",
      "22 application_type_Joint App 1020552\n",
      "23 term_ 60 months 1020552\n",
      "24 verification_status_Source Verified 1020552\n"
     ]
    }
   ],
   "source": [
    "has_data = {}\n",
    "for column in reduced_df.columns:\n",
    "    has_data[column] = len(reduced_df[column].dropna())\n",
    "has_data\n",
    "\n",
    "order_has_data=sorted(has_data, key=lambda dict_key: has_data[dict_key])\n",
    "\n",
    "top_sparse=25\n",
    "for i,j in zip(range(top_sparse),order_has_data[0:top_sparse]):\n",
    "    print(i,j, has_data[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020552, 44)\n",
      "14988 1020552\n"
     ]
    }
   ],
   "source": [
    "nonnan_df=reduced_df.fillna(0)\n",
    "#nonnan_df=reduced_df.drop(columns=order_has_data[0:4])\n",
    "print(nonnan_df.shape)\n",
    "print(len(reduced_df.dropna()),len(nonnan_df.dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020552, 44)\n",
      "loan_status_Fully Paid 2 [1 0]\n",
      "application_type_Joint App 2 [0 1]\n",
      "term_ 60 months 2 [0 1]\n",
      "verification_status_Source Verified 2 [0 1]\n",
      "verification_status_Verified 2 [1 0]\n",
      "home_ownership_MORTGAGE 2 [0 1]\n",
      "home_ownership_NONE 2 [0 1]\n",
      "home_ownership_OTHER 2 [0 1]\n",
      "home_ownership_OWN 2 [0 1]\n",
      "home_ownership_RENT 2 [1 0]\n",
      "purpose_credit_card 2 [1 0]\n",
      "purpose_debt_consolidation 2 [0 1]\n",
      "purpose_educational 2 [0 1]\n",
      "purpose_home_improvement 2 [0 1]\n",
      "purpose_house 2 [0 1]\n",
      "purpose_major_purchase 2 [0 1]\n",
      "purpose_medical 2 [0 1]\n",
      "purpose_moving 2 [0 1]\n",
      "purpose_other 2 [0 1]\n",
      "purpose_renewable_energy 2 [0 1]\n",
      "purpose_small_business 2 [0 1]\n",
      "purpose_vacation 2 [0 1]\n",
      "purpose_wedding 2 [0 1]\n",
      "grade 7 [2 3 1 5 6 4 7]\n",
      "inq_last_6mths 9 [1. 5. 2. 0. 3. 4. 6. 7. 8.]\n",
      "emp_length 11 [10.  0.  1.  3.  8.  9.  4.  5.  6.  2.  7.]\n",
      "inq_fi 29 [ 0.  2.  1.  5.  3.  4.  6. 16.  7.  9. 10. 11. 13. 17.  8. 12. 14. 15.\n",
      " 24. 20. 21. 18. 19. 23. 28. 22. 25. 27. 32.]\n",
      "delinq_2yrs 30 [ 0.  2.  3.  1.  4.  6.  5.  8.  7.  9. 11. 15. 13. 10. 12. 17. 18. 29.\n",
      " 24. 14. 21. 22. 19. 16. 30. 26. 20. 27. 39. 25.]\n",
      "pub_rec 34 [ 0.  1.  2.  3.  4.  5.  6.  9.  8.  7. 11. 49. 10. 54. 12. 18. 19. 16.\n",
      " 15. 40. 63. 13. 21. 34. 17. 20. 86. 14. 46. 47. 24. 25. 28. 22.]\n",
      "fico_est 40 [737.  742.  692.  697.  732.  662.  677.  727.  712.  707.  722.  667.\n",
      " 672.  762.  687.  757.  682.  702.  792.  752.  717.  767.  747.  772.\n",
      " 782.  777.  797.  812.  802.  817.  787.  807.  827.  822.  632.  627.\n",
      " 832.  842.  847.5 837. ]\n",
      "open_acc 82 [ 3.  2. 10. 15.  9.  7.  4. 11. 14. 12. 20.  8.  6. 17.  5. 13. 16. 30.\n",
      " 21. 18. 19. 27. 23. 34. 25. 22. 24. 26. 32. 28. 29. 33. 31. 39. 35. 36.\n",
      " 38. 44. 41. 42. 40.  1. 37. 45. 49. 53. 51. 43.  0. 62. 46. 48. 50. 52.\n",
      " 54. 47. 76. 58. 55. 84. 75. 61. 67. 57. 68. 70. 60. 56. 64. 79. 59. 74.\n",
      " 90. 65. 77. 81. 71. 63. 80. 72. 86. 66.]\n",
      "mths_since_last_record 124 [  0. 113. 105.  97.  33.  93.  52.  85.  90.  91. 114.  92. 117.  87.\n",
      "  45.  83. 118.  38. 101. 100. 112. 110.  88.  79.  77. 107. 102.  98.\n",
      "  95. 103.  96. 116. 111.  89. 108.  29. 106. 115.  53.  86.  57.  63.\n",
      "  94. 109.  99. 104.  76.  61.  28.  23.  75.  47.  82.  21.  62.  44.\n",
      "  80.  67. 119.  42.  34.  66.  58.  22.  56.  72.  64.  50.  69.  49.\n",
      "  74.  35.  12.  26.  78.  54.  37.  73.  11.  31.  59.  32.  81.  68.\n",
      "  55.  39.  51.  70.  30.  41.  71.  40.  43.  27.  65.  46.  19.  17.\n",
      "  25.  13.  48.  36.   7.  60.  14.   6.  18.  20. 120. 129.   5.  24.\n",
      "  84.  15.  10.  16.   8.   9.   3. 121.   4.   1.   2. 123.]\n",
      "total_acc 137 [  9.   4.  10.  37.  38.  12.  11.  13.   3.  23.  34.  29.  28.  42.\n",
      "  14.  22.  21.  17.   7.  31.  44.  26.  16.   6.  18.  27.  24.  25.\n",
      "  40.  35.   8.  20.  15.  19.  36.  51.  32.  30.  33.  46.   5.  61.\n",
      "  56.  50.  41.  39.  79.  62.  43.  47.  53.  45.  60.  55.  52.  58.\n",
      "  54.  57.  49.  63.  48.  59.  77.  87.  75.  72.  64.  67.  78.  76.\n",
      "  74.  66.  81.  90.  80.  71.  69.  73.  70.  68.  65.   2. 105.  83.\n",
      "  84.  98.  88.  82.  91.  99.  86.  93.  92.  96. 101. 150.  95.  85.\n",
      "  89. 156. 106.  97. 119. 124. 100.  94. 121. 102. 117. 116. 118. 111.\n",
      " 112. 125. 110. 135. 104. 151. 130. 107. 113. 169. 129. 126. 137. 103.\n",
      " 109. 138. 162. 114. 108. 176. 115. 133. 120. 144. 122.]\n",
      "mths_since_last_delinq 157 [  0.  35.  38.  61.   8.  20.  18.  68.  45.  48.  41.  40.  74.  25.\n",
      "  53.  39.  10.  26.  56.  77.  28.  52.  24.  16.  60.  54.  23.   9.\n",
      "  11.  13.  65.  19.  80.  22.  59.  79.  44.  64.  57.  14.  63.  49.\n",
      "  15.  73.  70.  29.  51.   5.  75.  55.   2.  30.  47.  33.  69.   4.\n",
      "  43.  21.  27.  46.  81.  78.  82.  31.  76.  62.  72.  42.  50.   3.\n",
      "  12.  67.  36.  34.  58.  17.  71.  66.  32.   6.  37.   7.   1.  83.\n",
      "  86. 115.  96. 103. 120. 106.  89. 107.  85.  97.  95. 110.  84. 135.\n",
      "  88.  87. 122.  91. 146. 134. 114.  99.  93. 127. 101.  94. 102. 129.\n",
      " 113. 139. 131. 156. 143. 109. 119. 149. 118. 130. 148. 126.  90. 141.\n",
      " 116. 100. 152.  98.  92. 108. 133. 104. 111. 105. 170. 124. 136. 180.\n",
      " 188. 140. 151. 159. 112. 171. 142. 125. 117. 123. 176. 137. 121. 158.\n",
      " 192. 132. 160.]\n",
      "mths_since_last_major_derog 165 [  0.  53.  34.  69.  71.  54.   7.  16.  33.  45.  59.  11.   8.  56.\n",
      "  50.  32.  76.  70.  39.  49.  64.  62.  74.  52.  46.  60.  51.  77.\n",
      "  27.  72.  22.  48.  58.  10.  73.  23.  61.  35.  57.  40.  18.  25.\n",
      "  63.  21.  47.  41.  80.  68.  44.  31.  28.  65.  30.  13.  15.  75.\n",
      "  26.  67.  12.  81.   5.  14.   6.  19.  43.  29.  42.  37.  38.  17.\n",
      "   4.  24.   9.  79.  66.  20.  36. 110.   1.  84.  78.  55.   2.   3.\n",
      "  82. 135. 152.  92. 115.  88.  95. 100. 123. 106.  83. 102.  94.  87.\n",
      "  85. 122.  89. 109.  86.  91. 146. 134. 114.  99.  97.  93.  96.  90.\n",
      " 165. 127. 119. 101. 124. 129. 113. 120. 139. 131. 112. 156. 143. 149.\n",
      " 118. 130. 104. 111. 148. 126. 141. 116. 133. 108.  98. 107. 147. 121.\n",
      " 154. 105. 103. 162. 140. 170. 136. 180. 188. 151. 159. 137. 117. 171.\n",
      " 142. 125. 132. 153. 145. 176. 150. 158. 197. 192. 160.]\n",
      "int_rate 616 [10.65 15.27 15.96 13.49 12.69  7.9  18.64 21.28 14.65  9.91 16.29  6.03\n",
      " 11.71 12.42 14.27 16.77  7.51  8.9  18.25  6.62 19.91 17.27 17.58 21.67\n",
      " 19.42 22.06 20.89 20.3  23.91 19.03 23.52 23.13 22.74 22.35 24.11  6.\n",
      " 22.11  7.49 11.99  5.99 10.99  9.99 18.79 11.49  8.49 15.99 16.49  6.99\n",
      " 12.99 15.23 14.79  5.42 10.59 17.49 15.62 21.36 19.29 13.99 18.39 16.89\n",
      " 17.99 20.62 20.99 22.85 19.69 20.25 23.22 21.74 22.48 23.59 12.62 18.07\n",
      " 11.63  7.91  7.42 11.14 20.2  12.12 19.39 16.11 17.54 22.64 13.84 16.59\n",
      " 17.19 12.87 20.69  9.67 21.82 19.79 18.49 22.94 24.59 24.4  21.48 14.82\n",
      " 14.17  7.29 17.88 20.11 16.02 17.51 13.43 14.91 13.06 15.28 15.65 17.14\n",
      " 11.11 10.37 16.4   7.66 10.   18.62 10.74  5.79  6.92  9.63 14.54 12.68\n",
      " 19.36 13.8  18.99 21.59 20.85 21.22 19.74 20.48  6.91 12.23 12.61 10.36\n",
      "  6.17  6.54  9.25 16.69 15.95  8.88 13.35  9.62 16.32 12.98 14.83 13.72\n",
      " 14.09 14.46 20.03 17.8  15.2  15.57 18.54 19.66 17.06 18.17 17.43 20.4\n",
      " 20.77 18.91 21.14 17.44 13.23  7.88 11.12 13.61 10.38 17.56 17.93 15.58\n",
      " 13.98 14.84 15.21  6.76  6.39 11.86  7.14 14.35 16.82 10.75 14.72 16.45\n",
      " 18.67 20.53 19.41 20.16 21.27 18.3  19.04 20.9  21.64 12.73 10.25 13.11\n",
      " 10.62 13.48 14.59 16.07 15.7   9.88 11.36 15.33 13.85 14.96 14.22  7.74\n",
      " 13.22 13.57  8.59 17.04 14.61  8.94 12.18 11.83 11.48 16.35 13.92 15.31\n",
      " 14.26 19.13 12.53 16.7  16.   17.39 18.09  7.4  18.43 17.74  7.05 20.52\n",
      " 20.86 19.47 18.78 21.21 19.82 20.17 13.16  8.   13.47 12.21 16.63  9.32\n",
      " 12.84 11.26 15.68 15.37 10.95 11.89 14.11 13.79  7.68 11.58  7.37 16.95\n",
      " 15.05 18.53 14.74 14.42 18.21 17.26 18.84 17.9  19.16 13.67  9.38 12.72\n",
      " 13.36 11.46 10.51  9.07 13.04 11.78 12.41 10.83 12.09 17.46 14.3  17.15\n",
      " 15.25 10.2  15.88 14.93 16.2  18.72 14.62  8.32 14.12 10.96 10.33 10.01\n",
      " 12.86 11.28 11.59  8.63 12.54 12.22 11.91 15.38 16.96 13.17  9.7  16.33\n",
      " 14.75 15.07 16.01 10.71 10.64  9.76 11.34 10.39 13.87 11.03 11.66 13.24\n",
      " 10.08  9.45 13.55 12.29 11.97 12.92 15.45 14.5  14.18 15.13 16.08 15.76\n",
      " 17.03 17.34 16.71  9.83 13.62 10.46  9.51  9.2  13.3  10.78  7.75  8.38\n",
      " 12.36 12.67 11.72 13.93  8.07  7.43 12.04 14.25 14.88 11.41 11.09 10.14\n",
      " 16.15 15.83  7.12 18.36  9.64  9.96 11.22  9.01  9.33 11.54 12.17 12.8\n",
      " 14.38 13.75 14.7  12.49 14.07 10.91 13.12 10.28  8.7  14.67 15.01 22.9\n",
      "  7.62 13.53 12.85 16.24 19.97 14.47 14.98 19.22 20.5  15.61 23.4  17.57\n",
      " 16.99 23.7  22.4  25.89 25.8  24.08 24.99 26.06 25.99 25.57 24.5  25.83\n",
      " 17.76 15.1  17.1  21.7  19.52 19.2  18.55 23.1  21.    6.97  8.6  13.68\n",
      " 16.78 11.55 22.2  18.85  9.71 14.33 15.22 22.7  13.05 23.5  21.6  12.35\n",
      " 20.8  24.89 21.15 20.31 25.28 17.77 19.05 10.16 19.72 23.28 15.8  18.75\n",
      " 23.76 20.49 23.83 24.7  23.63 21.98 22.95 22.47 21.49 24.83 21.97 15.81\n",
      " 22.45 22.78 23.33 19.99 24.2  24.76 24.33 23.26 24.52 14.28 12.39 13.66\n",
      " 15.59 14.31 11.44 17.86 14.99 10.49  9.49 22.99  8.19 21.99  8.67 19.24\n",
      " 23.99  6.49 22.15  7.69 18.24 11.67  8.39 10.15 14.49  9.17 23.43 13.65\n",
      " 14.64 21.18 18.92 14.16 17.97  5.32 19.89 15.77 14.85 13.44  9.8  12.88\n",
      " 24.24 19.48 26.99 27.49 27.99 28.49 25.09 28.99  7.89 16.55  7.26 14.48\n",
      " 13.18 15.41  6.89 12.59  6.24 18.2  27.88 27.31 26.77 12.05  8.18 16.9\n",
      " 13.33 11.53 19.19 25.78  5.93  6.68 11.47  9.16 19.53  7.39  9.75 20.75\n",
      " 28.34 26.57 28.14 28.67 25.88 27.34 15.29 14.77 22.39 24.49 12.79 27.79\n",
      "  7.99 26.49 28.18 25.29 25.69  7.59  8.99 28.88 29.67 29.96 30.99 23.32\n",
      " 25.11 26.14 25.44 25.65 28.69 12.74  7.24  8.24 25.49 11.39 26.24 29.99\n",
      " 24.74 30.89 29.49 30.84 30.79 30.74 30.49 30.94  7.07  7.97  7.35 24.85\n",
      " 14.08  9.93 30.65 21.45  9.44 18.06 10.42 13.59  7.21 20.   17.09 26.3\n",
      " 25.82 23.88 22.91 29.69 30.75 30.17 28.72  6.08  6.72  7.34 15.04 11.98\n",
      " 17.47  7.96 13.58 18.45 10.41  6.07 25.81 21.85 10.9   9.92  9.43  6.71\n",
      " 23.87  5.31 20.39 24.84]\n",
      "revol_util 1335 [ 83.7   9.4  98.5 ... 123.5 125.  120.9]\n",
      "loan_amnt 1526 [ 5000.  2500.  2400. ... 36375. 38050. 35725.]\n",
      "earliest_cr_line 2711 [ 9830.  4627.  3682. ... 21366. 20729. 18111.]\n",
      "dti 5647 [27.65  1.    8.72 ... 98.8  69.62 65.24]\n",
      "annual_inc 53722 [ 24000.    30000.    12252.   ...  52979.94 162537.    89625.39]\n",
      "revol_bal 75740 [ 13648.   1687.   2956. ...  61950.  61356. 141952.]\n",
      "installment 76852 [ 162.87   59.83   84.33 ...  162.95  605.   1142.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_pymnt 968429 [ 5863.1551867   1014.53        3005.66684414 ...  7428.09944457\n",
      " 12483.1542331  14662.94701135]\n"
     ]
    }
   ],
   "source": [
    "nonnan_df=nonnan_df.dropna()\n",
    "print(nonnan_df.shape)\n",
    "\n",
    "n_options = {}\n",
    "for column in nonnan_df.columns:\n",
    "    n_options[column] = len(nonnan_df[column].unique())\n",
    "#n_options\n",
    "order_n_options=sorted(n_options, key=lambda dict_key: n_options[dict_key])\n",
    "\n",
    "for i in order_n_options[0:49]:\n",
    "    print(i, n_options[i],nonnan_df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.020552e+06\n",
       "mean              inf\n",
       "std               NaN\n",
       "min      1.231699e-04\n",
       "25%      4.688933e-02\n",
       "50%      7.284552e-02\n",
       "75%      1.057535e-01\n",
       "max               inf\n",
       "Name: percent_of_income, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonnan_df['percent_of_income'] = nonnan_df['installment']*12/nonnan_df['annual_inc']\n",
    "nonnan_df['percent_of_income'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonnan_df = nonnan_df[nonnan_df['application_type_Joint App']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional factors to remove\n",
    "to_remove=[]\n",
    "if 'installment' not in to_remove:\n",
    "    #to_remove += ['installment']\n",
    "    to_remove += ['total_pymnt','loan_amnt','grade','loan_status_Fully Paid']\n",
    "features = list(set(nonnan_df.columns) - set(to_remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's work with training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1873317, 152) (1011023, 45)\n",
      "['delinq_2yrs', 'home_ownership_MORTGAGE', 'dti', 'home_ownership_OTHER', 'application_type_Joint App', 'purpose_renewable_energy', 'purpose_house', 'term_ 60 months', 'inq_last_6mths', 'purpose_moving', 'earliest_cr_line', 'fico_est', 'home_ownership_NONE', 'purpose_educational', 'purpose_other', 'inq_fi', 'verification_status_Verified', 'purpose_medical', 'total_acc', 'emp_length', 'home_ownership_RENT', 'installment', 'home_ownership_OWN', 'purpose_debt_consolidation', 'revol_bal', 'mths_since_last_record', 'purpose_wedding', 'purpose_credit_card', 'verification_status_Source Verified', 'purpose_major_purchase', 'mths_since_last_major_derog', 'pub_rec', 'revol_util', 'purpose_small_business', 'open_acc', 'percent_of_income', 'mths_since_last_delinq', 'purpose_home_improvement', 'annual_inc', 'purpose_vacation', 'int_rate']\n",
      "Index(['delinq_2yrs', 'home_ownership_MORTGAGE', 'dti', 'home_ownership_OTHER',\n",
      "       'application_type_Joint App', 'purpose_renewable_energy',\n",
      "       'purpose_house', 'term_ 60 months', 'inq_last_6mths', 'purpose_moving',\n",
      "       'earliest_cr_line', 'fico_est', 'home_ownership_NONE',\n",
      "       'purpose_educational', 'purpose_other', 'inq_fi',\n",
      "       'verification_status_Verified', 'purpose_medical', 'total_acc',\n",
      "       'emp_length', 'home_ownership_RENT', 'installment',\n",
      "       'home_ownership_OWN', 'purpose_debt_consolidation', 'revol_bal',\n",
      "       'mths_since_last_record', 'purpose_wedding', 'purpose_credit_card',\n",
      "       'verification_status_Source Verified', 'purpose_major_purchase',\n",
      "       'mths_since_last_major_derog', 'pub_rec', 'revol_util',\n",
      "       'purpose_small_business', 'open_acc', 'percent_of_income',\n",
      "       'mths_since_last_delinq', 'purpose_home_improvement', 'annual_inc',\n",
      "       'purpose_vacation', 'int_rate'],\n",
      "      dtype='object')\n",
      "(647054, 41) (161764, 41) (202205, 41)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape,nonnan_df.shape)\n",
    "\n",
    "# need to look at interest rate as well!!!\n",
    "#y=nonnan_df['total_pymnt']/(nonnan_df['installment']*36 + nonnan_df['installment']*nonnan_df['term_ 60 months']*24)\n",
    "y=nonnan_df['loan_status_Fully Paid']\n",
    "#y=nonnan_df['total_pymnt']/nonnan_df['loan_amnt']\n",
    "print(features)\n",
    "traintest_df=nonnan_df[features]\n",
    "print(traintest_df.columns)\n",
    "\n",
    "Xscaler = StandardScaler()\n",
    "Xscaler.fit_transform(traintest_df)\n",
    "\n",
    "X_traintune, X_test, y_traintune, y_test = train_test_split(\n",
    "    traintest_df,y,test_size=0.2)#,random_state=42)#,stratify=nonnan_df[['loan_status']])\n",
    "\n",
    "X_train, X_tune, y_train, y_tune = train_test_split(\n",
    "    X_traintune,y_traintune,test_size=0.2)#,random_state=42)#,stratify=nonnan_df[['loan_status']])\n",
    "\n",
    "print(X_train.shape,X_tune.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7955644925980913 0.40328871988163834\n"
     ]
    }
   ],
   "source": [
    "print(y.mean(),y.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "\n",
      "Best decision tree score: 0.7971452150825125 occurs at depth: 7\n",
      "Decision Tree test prediction accuracy: 0.796973\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#kfold=KFold(5, shuffle=True)\n",
    "\n",
    "parameters = {'max_depth':range(1,10)}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), parameters, n_jobs=4,cv=5)\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "dtclf = clf.best_estimator_\n",
    "\n",
    "results=clf.cv_results_\n",
    "\n",
    "print(dtclf)\n",
    "\n",
    "print(\"\\nBest decision tree score: {} occurs at depth: {}\".format(\n",
    "    clf.best_score_, clf.best_params_['max_depth']))\n",
    "\n",
    "print(\"Decision Tree test prediction accuracy: %f\" % accuracy_score(dtclf.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest training prediction accuracy: 0.798372\n",
      "Random Forest test prediction accuracy: 0.797097\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "rfclf = RandomForestClassifier(n_estimators=25,max_depth=10)\n",
    "rfclf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest training prediction accuracy: %f\" % accuracy_score(rfclf.predict(X_train),y_train))\n",
    "\n",
    "print(\"Random Forest test prediction accuracy: %f\" % accuracy_score(rfclf.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost test prediction accuracy: 0.796959\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "basic=DecisionTreeClassifier(max_depth=3)\n",
    "abclf = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=0.05,\n",
    "                         base_estimator=basic)\n",
    "# Train model\n",
    "abclf.fit(X_train, y_train)\n",
    "print(\"Adaboost test prediction accuracy: %f\" % accuracy_score(abclf.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic model accuracy: 0.7963601295714745\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "fitted_logreg = LogisticRegressionCV().fit(X_train, y_train)\n",
    "print(\"Logistic model accuracy: {}\".format(fitted_logreg.score(X_test, y_test)))\n",
    "\n",
    "#print(\"\\nLogistic coefficients weights:\")\n",
    "#print(*X_train, sep=' ')\n",
    "#print(*fitted_logreg.coef_[0], sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the models\n",
    "ensemble_dict={}\n",
    "ensemble_dict[\"DT\"]=dtclf\n",
    "ensemble_dict[\"RF\"]=rfclf\n",
    "ensemble_dict[\"Log\"]=fitted_logreg\n",
    "ensemble_dict[\"Ada\"]=abclf\n",
    "\n",
    "import pickle\n",
    "with open(\"ensemble.pkl\", 'wb') as outfile:\n",
    "    pickle.dump(ensemble_dict,outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161764, 4) (202205, 4) (161764, 41) (202205, 41)\n",
      "(161764, 45) (202205, 45)\n"
     ]
    }
   ],
   "source": [
    "with open(\"ensemble.pkl\", 'rb') as infile:\n",
    "    model_dict = pickle.load(infile)\n",
    "    \n",
    "ensemble_tune=pd.DataFrame()\n",
    "ensemble_test=pd.DataFrame()\n",
    "for k,v in model_dict.items():\n",
    "    ensemble_tune[k]=v.predict_proba(X_tune)[:,1]\n",
    "    ensemble_test[k]=v.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(ensemble_tune.shape,ensemble_test.shape,X_tune.shape,X_test.shape)\n",
    "eX_tune=X_tune.reset_index(drop=True)\n",
    "eX_test=X_test.reset_index(drop=True)\n",
    "ey_tune=y_tune.reset_index(drop=True)\n",
    "ey_test=y_test.reset_index(drop=True)\n",
    "\n",
    "# your code here\n",
    "augmented_tune=pd.concat((ensemble_tune,eX_tune),axis=1)\n",
    "augmented_test=pd.concat((ensemble_test,eX_test),axis=1)\n",
    "\n",
    "print(augmented_tune.shape,augmented_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7949457233995203\n"
     ]
    }
   ],
   "source": [
    "ensemble_clf=DecisionTreeClassifier(max_depth=10).fit(augmented_tune,ey_tune)\n",
    "print(ensemble_clf.score(augmented_test,ey_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798808140253703\n"
     ]
    }
   ],
   "source": [
    "ensemble_rfclf = RandomForestClassifier(n_estimators=25,max_depth=10).fit(augmented_tune,ey_tune)\n",
    "print(ensemble_rfclf.score(augmented_test,ey_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic model accuracy: 0.7963799114759773\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "ensemble_logreg = LogisticRegressionCV().fit(augmented_tune, ey_tune)\n",
    "print(\"Logistic model accuracy: {}\".format(ensemble_logreg.score(augmented_test, ey_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost test prediction accuracy: 0.798783\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "basic=DecisionTreeClassifier(max_depth=3)\n",
    "ensemble_abclf = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=0.05,\n",
    "                         base_estimator=basic)\n",
    "# Train model\n",
    "ensemble_abclf.fit(augmented_tune, ey_tune)\n",
    "print(\"Adaboost test prediction accuracy: %f\" % accuracy_score(ensemble_abclf.predict(augmented_test),ey_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_final = pd.DataFrame(index=traintest_df.index)\n",
    "\n",
    "for key in ensemble_dict.keys():\n",
    "    data_for_final[key] = ensemble_dict[key].predict(traintest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_for_final, open(\"pred_for_final.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
